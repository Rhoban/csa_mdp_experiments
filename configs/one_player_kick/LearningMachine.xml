<LearningMachine>
  <LearningMachineBlackBox>
    <problem>
      <one_player_kick>
        <policy>
          <mixed_approach>
            <nearby_policy>
              <fa_policy>
                <path>approach_policy/best_policy.data</path>
              </fa_policy>
            </nearby_policy>
          </mixed_approach>
        </policy>
      </one_player_kick>
    </problem>
    <learner>
      <ModelBasedLearner>
        <model>
          <one_player_kick>
            <policy>
              <mixed_approach>
                <nearby_policy>
                  <fa_policy>
                    <path>approach_policy/best_policy.data</path>
                  </fa_policy>
                </nearby_policy>
              </mixed_approach>
            </policy>
          </one_player_kick>
        </model>
        <reward_predictor>
          <MonteCarloPredictor>
            <nb_steps>20</nb_steps>
            <nb_predictions>20</nb_predictions>
          </MonteCarloPredictor>
        </reward_predictor>
        <value_trainer>PWCForestTrainer</value_trainer>
        <action_optimizer>
          <BasicOptimizer>
            <trainer>PWCForestTrainer</trainer>
            <nb_simulations>10</nb_simulations>
            <nb_actions>100</nb_actions>
            <nb_additional_steps>0</nb_additional_steps>
          </BasicOptimizer>
        </action_optimizer>
        <policy_trainer>PWLForestTrainer</policy_trainer>
      </ModelBasedLearner>
    </learner>
    <save_run_logs>true</save_run_logs>
    <nb_threads>40</nb_threads>
    <nb_runs>5050</nb_runs>
    <nb_steps>20</nb_steps>
    <time_budget>1800</time_budget>
  </LearningMachineBlackBox>
</LearningMachine>
